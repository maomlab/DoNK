#!/bin/bash

#SBATCH --job-name=
#SBATCH --account=
#SBATCH --partition=
#SBATCH --cpus-per-task=
#SBATCH --nodes=
#SBATCH --ntasks-per-node=
#SBATCH --mem-per-cpu=
#SBATCH --time=
#SBATCH --mail-type=BEGIN,END
#SBATCH --error=
#SBATCH --out=
#SBATCH --mail-user=
#SBATCH --array= ## range (1-n) where n is the number of array jobs you have (# of lines in task.txt)

# tasks.txt should contain a list of directories (one on each line). each of these directories should contain a results directory generated by DOCK38
# the output is a dirlist file, which contains the directories of docked info of results. dirlist is a file used as input for most of the DOCK38 analysis scripts 

dir=$(cat tasks.txt | sed -n "$SLURM_ARRAY_TASK_ID p") 

cd $dir

# add all of the directories in the results dir to dirlist
ls -d *results/* > dirlist

# remove file_list, joblist, and logs from the dirlist 
sed -i '/file_list/d' dirlist
sed -i '/joblist/d' dirlist
sed -i '/logs/d' dirlist
